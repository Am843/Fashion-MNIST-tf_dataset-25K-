# -*- coding: utf-8 -*-
"""fashion_MNIST_tf_dataset(25K).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GPxUWHj65aqykLFG9BYeLH2DWRb0iFoB
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

fashin_MNIST = tf.keras.datasets.fashion_mnist
(train_feature,train_label), (test_feature, test_label) = fashin_MNIST.load_data()

# vitualize

fig, ax = plt.subplots(nrows=14,ncols=12, figsize=(108,72))
for i in range(14):
  for j in range(12):

    ax[i, j].imshow(train_feature[i*j])
plt.savefig("Fashion MNIST training dataset")
plt.show()

train_feature.shape

# preprocessing data (scaling)
train_feature = train_feature/255
test_feature = test_feature/255



def createModel(learning_rate):
  # create model
  model = tf.keras.Sequential()
  # add convulution layers + pooling layser
  model.add(tf.keras.layers.Conv2D(16, (3), activation="relu", input_shape=(28,28,1), padding="valid", kernel_regularizer="l2"))
  model.add(tf.keras.layers.MaxPool2D(2))
  model.add(tf.keras.layers.Conv2D(16, (3), activation="relu", input_shape=(28,28, 1),padding="valid", kernel_regularizer="l2"))
  model.add(tf.keras.layers.MaxPool2D(2))


  #  Flatting image from 2D -> 1D
  model.add(tf.keras.layers.Flatten())
  #  Add Dense Layers
  model.add(tf.keras.layers.Dense(64, "relu", activity_regularizer="l2"))
  model.add(tf.keras.layers.Dense(10, "softmax"))

  # Compiling Model
  model.compile(optimizer="Adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

  return model

def trainModel(model,train_feature, train_label,batch_size, epochs):
  #  Fit data to train model
  history = model.fit(train_feature, train_label, batch_size=batch_size, epochs=epochs, validation_split=0.1)

  #  get history
  hist = pd.DataFrame(history.history)

  #  get mae history
  train_loss, train_accuracy = hist["loss"], hist["accuracy"]
  val_loss, val_accuracy = hist["val_loss"], hist["val_accuracy"]

  #  get epoch history
  epoch = history.epoch

  return train_loss,train_accuracy,val_loss,val_accuracy, epoch

def plot_loss_curve(train_loss, train_accuracy, val_loss, val_accuracy, epochs):
  plt.figure()
  plt.title("Loss\\Accuracy Curve")
  plt.xlabel("epochs")
  plt.ylabel("Loss\\Accuracy")

  plt.plot(epochs, train_loss, label="train_loss")
  plt.plot(epochs, train_accuracy, label="training_accuracy")
  plt.plot(epochs, val_loss, label="val_loss")
  plt.plot(epochs, val_accuracy, label="val_accuracy")
  plt.legend()
  plt.savefig("Fashion MNIST Training Loss\\Accuracy")
  plt.show()

learning_rate=0.01
batch_size = 16
epochs = 25

model = createModel(learning_rate)
train_loss, train_acc, val_loss, val_acc, epoch = trainModel(model, train_feature, train_label, batch_size, epochs)
plot_loss_curve(train_loss=train_loss,train_accuracy=train_acc, val_loss=val_loss, val_accuracy=val_acc, epochs=epoch)

plot_loss_curve(train_loss=train_loss,train_accuracy=train_acc, val_loss=val_loss, val_accuracy=val_acc, epochs=epoch)

model.summary()

model.evaluate(test_feature/255, test_label)